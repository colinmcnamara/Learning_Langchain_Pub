{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/colinmcnamara/Learning_Langchain_Pub/blob/main/caching_embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install langchain openai tiktoken faiss-gpu\n",
        "# user pip install -q faiss-cpu if you don't have GPU's on your instance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_oFopNDjhF7",
        "outputId": "09c082f4-f9f7-4c29-9ace-208c8c04834e"
      },
      "id": "G_oFopNDjhF7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf4061ce",
      "metadata": {
        "id": "bf4061ce"
      },
      "source": [
        "# Caching Embeddings\n",
        "\n",
        "Embeddings can be stored or temporarily cached to avoid needing to recompute them.\n",
        "\n",
        "Caching embeddings can be done using a `CacheBackedEmbeddings`.\n",
        "\n",
        "The cache backed embedder is a wrapper around an embedder that caches\n",
        "embeddings in a key-value store.\n",
        "\n",
        "The text is hashed and the hash is used as the key in the cache.\n",
        "\n",
        "\n",
        "The main supported way to initialized a `CacheBackedEmbeddings` is `from_bytes_store`. This takes in the following parameters:\n",
        "\n",
        "- underlying_embedder: The embedder to use for embedding.\n",
        "- document_embedding_cache: The cache to use for storing document embeddings.\n",
        "- namespace: (optional, defaults to `\"\"`) The namespace to use for document cache. This namespace is used to avoid collisions with other caches. For example, set it to the name of the embedding model used.\n",
        "\n",
        "**Attention**: Be sure to set the `namespace` parameter to avoid collisions of the same text embedded using different embeddings models."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q colab_env"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBNVEix8j8XI",
        "outputId": "5b540f76-63bf-48de-ee19-4b726b600fbc"
      },
      "id": "aBNVEix8j8XI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for colab_env (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import colab_env\n",
        "import langchain\n",
        "import openai\n",
        "import os"
      ],
      "metadata": {
        "id": "66jDgf-rXmvk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4aafd55-0690-4334-bfd6-dc614ecaa36e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "id": "66jDgf-rXmvk"
    },
    {
      "cell_type": "code",
      "source": [
        "openai_api_key=os.environ['OPENAI_API_KEY']"
      ],
      "metadata": {
        "id": "8WsfvyC1YC96"
      },
      "execution_count": null,
      "outputs": [],
      "id": "8WsfvyC1YC96"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a463c3c2-749b-40d1-a433-84f68a1cd1c7",
      "metadata": {
        "tags": [],
        "id": "a463c3c2-749b-40d1-a433-84f68a1cd1c7"
      },
      "outputs": [],
      "source": [
        "from langchain.storage import InMemoryStore, LocalFileStore, RedisStore\n",
        "from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ddf07dd-3e72-41de-99d4-78e9521e272f",
      "metadata": {
        "id": "9ddf07dd-3e72-41de-99d4-78e9521e272f"
      },
      "source": [
        "## Using with a vectorstore\n",
        "\n",
        "First, let's see an example that uses the local file system for storing embeddings and uses FAISS vectorstore for retrieval."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e4314d8-88ef-4f52-81ae-0be771168bb6",
      "metadata": {
        "id": "9e4314d8-88ef-4f52-81ae-0be771168bb6"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e751f26-9b5b-4c10-843a-d784b5ea8538",
      "metadata": {
        "id": "3e751f26-9b5b-4c10-843a-d784b5ea8538"
      },
      "outputs": [],
      "source": [
        "underlying_embeddings = OpenAIEmbeddings()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30743664-38f5-425d-8216-772b64e7f348",
      "metadata": {
        "id": "30743664-38f5-425d-8216-772b64e7f348"
      },
      "outputs": [],
      "source": [
        "fs = LocalFileStore(\"./cache/\")\n",
        "\n",
        "cached_embedder = CacheBackedEmbeddings.from_bytes_store(\n",
        "    underlying_embeddings, fs, namespace=underlying_embeddings.model\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8cdf33c-321d-4d2c-b76b-d6f5f8b42a92",
      "metadata": {
        "id": "f8cdf33c-321d-4d2c-b76b-d6f5f8b42a92"
      },
      "source": [
        "The cache is empty prior to embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9ad627f-ced2-4277-b336-2434f22f2c8a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9ad627f-ced2-4277-b336-2434f22f2c8a",
        "outputId": "40a1d622-ad8e-41ff-e2a6-8a4d426f4e44"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "list(fs.yield_keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4effe04-b40f-42f8-a449-72fe6991cf20",
      "metadata": {
        "id": "a4effe04-b40f-42f8-a449-72fe6991cf20"
      },
      "source": [
        "Load the document, split it into chunks, embed each chunk and load it into the vector store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf958ac2-e60e-4668-b32c-8bb2d78b3c61",
      "metadata": {
        "id": "cf958ac2-e60e-4668-b32c-8bb2d78b3c61"
      },
      "outputs": [],
      "source": [
        "raw_documents = TextLoader(\"/content/gdrive/MyDrive/state_of_the_union.txt\").load()\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "documents = text_splitter.split_documents(raw_documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f526444b-93f8-423f-b6d1-dab539450921",
      "metadata": {
        "id": "f526444b-93f8-423f-b6d1-dab539450921"
      },
      "source": [
        "create the vectorstore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a1d7bb8-3b72-4bb5-9013-cf7729caca61",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a1d7bb8-3b72-4bb5-9013-cf7729caca61",
        "outputId": "91f4a9b1-b958-492d-d4b9-255b5be41ff5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.14 s, sys: 105 ms, total: 1.24 s\n",
            "Wall time: 3.3 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "db = FAISS.from_documents(documents, cached_embedder)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64fc53f5-d559-467f-bf62-5daef32ffbc0",
      "metadata": {
        "id": "64fc53f5-d559-467f-bf62-5daef32ffbc0"
      },
      "source": [
        "If we try to create the vectostore again, it'll be much faster since it does not need to re-compute any embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "714cb2e2-77ba-41a8-bb83-84e75342af2d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "714cb2e2-77ba-41a8-bb83-84e75342af2d",
        "outputId": "2014e5d1-1186-4229-9bff-289273f4525b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 59.4 ms, sys: 3.19 ms, total: 62.6 ms\n",
            "Wall time: 106 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "db2 = FAISS.from_documents(documents, cached_embedder)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1acc76b9-9c70-4160-b593-5f932c75e2b6",
      "metadata": {
        "id": "1acc76b9-9c70-4160-b593-5f932c75e2b6"
      },
      "source": [
        "And here are some of the embeddings that got created:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2ca32dd-3712-4093-942b-4122f3dc8a8e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2ca32dd-3712-4093-942b-4122f3dc8a8e",
        "outputId": "72ccf47f-c287-4c96-f388-9735cb0af8a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['text-embedding-ada-0025ba09d7e-6a58-5c76-b038-5d8636e5ea25',\n",
              " 'text-embedding-ada-00281426526-23fe-58be-9e84-6c7c72c8ca9a',\n",
              " 'text-embedding-ada-002b793db35-a909-5ba0-8c51-314dc776017d',\n",
              " 'text-embedding-ada-00201dbc21f-5e4c-5fb5-8d13-517dbe7a32d4',\n",
              " 'text-embedding-ada-002464862c8-03d2-5854-b32c-65a075e612a2']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "list(fs.yield_keys())[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "564c9801-29f0-4452-aeac-527382e2c0e8",
      "metadata": {
        "id": "564c9801-29f0-4452-aeac-527382e2c0e8"
      },
      "source": [
        "## In Memory\n",
        "\n",
        "This section shows how to set up an in memory cache for embeddings. This type of cache is primarily\n",
        "useful for unit tests or prototyping. Do **not** use this cache if you need to actually store the embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13bd1c5b-b7ba-4394-957c-7d5b5a841972",
      "metadata": {
        "tags": [],
        "id": "13bd1c5b-b7ba-4394-957c-7d5b5a841972"
      },
      "outputs": [],
      "source": [
        "store = InMemoryStore()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d99885f-99e1-498c-904d-6db539ac9466",
      "metadata": {
        "tags": [],
        "id": "9d99885f-99e1-498c-904d-6db539ac9466"
      },
      "outputs": [],
      "source": [
        "underlying_embeddings = OpenAIEmbeddings()\n",
        "embedder = CacheBackedEmbeddings.from_bytes_store(\n",
        "    underlying_embeddings, store, namespace=underlying_embeddings.model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "682eb5d4-0b7a-4dac-b8fb-3de4ca6e421c",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "682eb5d4-0b7a-4dac-b8fb-3de4ca6e421c",
        "outputId": "84db16a9-b728-497c-a94d-d28cce0d1b08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 31.4 ms, sys: 4.28 ms, total: 35.7 ms\n",
            "Wall time: 2.78 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "embeddings = embedder.embed_documents([\"hello\", \"goodbye\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95233026-147f-49d1-bd87-e1e8b88ebdbc",
      "metadata": {
        "id": "95233026-147f-49d1-bd87-e1e8b88ebdbc"
      },
      "source": [
        "The second time we try to embed the embedding time is only 2 ms because the embeddings are looked up in the cache."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f819c3ff-a212-4d06-a5f7-5eb1435c1feb",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f819c3ff-a212-4d06-a5f7-5eb1435c1feb",
        "outputId": "a2539dc8-541d-41b1-e8f3-dd3eede103e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2.58 ms, sys: 0 ns, total: 2.58 ms\n",
            "Wall time: 2.66 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "embeddings_from_cache = embedder.embed_documents([\"hello\", \"goodbye\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec38fb72-90a9-4687-a483-c62c87d1f4dd",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec38fb72-90a9-4687-a483-c62c87d1f4dd",
        "outputId": "20f68753-2aa6-431c-ecf5-c40acaa7c0e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "embeddings == embeddings_from_cache"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6cbe100-8587-4830-b207-fb8b524a9854",
      "metadata": {
        "id": "f6cbe100-8587-4830-b207-fb8b524a9854"
      },
      "source": [
        "## File system\n",
        "\n",
        "This section covers how to use a file system store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0070271-0809-4528-97e0-2a88216846f3",
      "metadata": {
        "tags": [],
        "id": "a0070271-0809-4528-97e0-2a88216846f3"
      },
      "outputs": [],
      "source": [
        "fs = LocalFileStore(\"./test_cache/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b20e9fe-f57f-4d7c-9f81-105c5f8726f4",
      "metadata": {
        "tags": [],
        "id": "0b20e9fe-f57f-4d7c-9f81-105c5f8726f4"
      },
      "outputs": [],
      "source": [
        "embedder2 = CacheBackedEmbeddings.from_bytes_store(\n",
        "    underlying_embeddings, fs, namespace=underlying_embeddings.model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "630515fd-bf5c-4d9c-a404-9705308f3a2c",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "630515fd-bf5c-4d9c-a404-9705308f3a2c",
        "outputId": "9bc86f12-c50a-4f15-fe83-2052abe00df3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 14.5 ms, sys: 1.27 ms, total: 15.8 ms\n",
            "Wall time: 522 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "embeddings = embedder2.embed_documents([\"hello\", \"goodbye\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30e6bb87-42c9-4d08-88ac-0d22c9c449a1",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30e6bb87-42c9-4d08-88ac-0d22c9c449a1",
        "outputId": "b842c43e-88de-4ed4-ca56-1fb7c1fa0ba8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3.83 ms, sys: 880 µs, total: 4.71 ms\n",
            "Wall time: 16.4 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "embeddings = embedder2.embed_documents([\"hello\", \"goodbye\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12ed5a45-8352-4e0f-8583-5537397f53c0",
      "metadata": {
        "id": "12ed5a45-8352-4e0f-8583-5537397f53c0"
      },
      "source": [
        "Here are the embeddings that have been persisted to the directory `./test_cache`.\n",
        "\n",
        "Notice that the embedder takes a namespace parameter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "658e2914-05e9-44a3-a8fe-3fe17ca84039",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "658e2914-05e9-44a3-a8fe-3fe17ca84039",
        "outputId": "025db3e5-1a57-4db9-aaf4-e8db1186132c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['text-embedding-ada-002e885db5b-c0bd-5fbc-88b1-4d1da6020aa5',\n",
              " 'text-embedding-ada-0026ba52e44-59c9-5cc9-a084-284061b13c80']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "list(fs.yield_keys())"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}